import os
import torch
import torch.nn as nn
from sentence_transformers import SentenceTransformer
import torch_geometric as tg
from torch_geometric.data import Data
from typing import Optional, Union
from utils.io import LogRedirectMixin, log
from utils.inspector import ModelInspector
from torch.fx import symbolic_trace
import numpy as np



class Graphicalor(LogRedirectMixin):
    def __init__(self, network:nn.Module, embedding_model:nn.Module = None, log_path:Optional[str] = None) -> None:
        super().__init__(log_path)
        self.network = network
        if not embedding_model:
            log("No embedding model provided. Using default model: all-MiniLM-L6-v2.", level="WARNING")
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        self.graph_A = None
        self.graph_B = []
        self.traced = symbolic_trace(self.network)
        self.extract_nodes_and_edges()
    
    def _get_layer(self, name:str, verbose:bool=True) -> nn.Module:
        """Get a specific layer of model.

        Args:
            name (str): Layer name, split by dot(.), especially, can be 'all'.

        Returns:
            nn.Module: Target layer
        """
        if name == 'all':
            return self.network
        else:
            name_list = name.split('.')
            tar = self.network
            for i in name_list:
                try:
                    i = eval(i)
                except:
                    pass
                if isinstance(i, str):
                    tar = getattr(tar, i)
                elif isinstance(i, int):
                    try:
                        tar = tar[i]
                    except:
                        pass
            return tar

    def embedding_node(self, node:dict, verbose:bool=True):
        """
        Generate an embedding for a node based on its description.

        This function generates a natural language description for a given node 
        in a neural network based on its type and index in the network. The 
        description is then encoded into a vector representation using a pre-trained 
        embedding model.

        Args:
            node (dict): A dictionary containing node information. Expected keys:
                - 'name' (str): The name of the node.
                - 'type' (str): The type of the node (e.g., 'conv', 'relu').
                - 'index' (int): The index of the node in the network.
            verbose (bool, optional): Whether to log the description of the node. Defaults to True.

        Returns:
            np.ndarray: A vector representation of the node's description, generated by the embedding model.

        Notes:
            - The function uses a mapping dictionary to associate node types with 
            natural language descriptions.
            - If the node type is not in the mapping, it defaults to "Other operator."
            - The node index is converted to a human-readable ordinal string (e.g., 'first', 'second').
        
        Example:
            node = {'name': 'conv1', 'type': 'conv', 'index': 1}
            embedding = self.embedding_node(node)
        """

        mapping = {
            'conv': 'Convolution module',
            'linear': 'Linear module',
            'fc': 'Linear module',
            'batch_norm': 'BatchNorm activation',
            'relu': 'ReLU activation',
            'max_pool': 'MaxPool function',
            'avg_pool': 'AvgPool function',
            'dropout': 'Dropout function',
            'softmax': 'Softmax function',
            'sigmoid': 'Sigmoid function',
            'tanh': 'Tanh function',
            'other': 'Other operator',
        }
        
        def get_key(name):
            for k in mapping.keys():
                if k in str(name).lower():
                    return k
            else:
                return 'other'
        def get_index_string(ind):
            if ind == 0:
                return 'input'
            if ind == 1:
                return 'first'
            if ind == 2:
                return 'second'
            if ind == 3:
                return 'third'
            if ind > 3:
                return f"{ind}th"
            
        description = f"The {get_index_string(node['index'])} layer, which is a {mapping[get_key(node['type'])]}."
        if node['parameters'].sum() == 0:
            param_des = "No parameters."
        else:
            param_des = f"Its parameters mean is {node['parameters'][0].item()}, standard deviation is {node['parameters'][1].item()}, minimum is {node['parameters'][2].item()}, maximum is {node['parameters'][3].item()}, total number of parameters is {node['parameters'][4].item()}."
        description += param_des
        log(f"Name: {node['name']} Description: {description}.")
        embbeding = torch.tensor(self.embedding_model.encode(description))
        return embbeding
    
    def extract_parameter_features(self, parameters:dict):
        """
        Extract fixed-length features from node parameters as a torch.Tensor.

        Args:
            parameters (dict): A dictionary of parameter tensors, typically from `module.named_parameters()`.

        Returns:
            torch.Tensor: A fixed-length tensor representing the parameters, 
                        or a zero tensor if no parameters are present.
        """
        if parameters is None:
            # No parameters: return zero vector
            return torch.zeros(5, dtype=torch.float32)
        all_params = parameters.flatten()
        mean = torch.mean(all_params)
        std = torch.std(all_params)
        min_val = torch.min(all_params)
        max_val = torch.max(all_params)
        param_count = torch.tensor(all_params.numel(), dtype=torch.float32)

        # Feature vector: [mean, std, min, max, param_count]
        return torch.tensor([mean, std, min_val, max_val, param_count], dtype=torch.float32)
    
    def extract_nodes_and_edges(self, verbose:bool=True):
        """Generate nodes and edges from the network.

        Args:
            verbose (bool, optional): If log verbose information. Defaults to True.

        Returns:
            nodes and edges.
        """
        nodes = {}
        graphb_nodes = []
        edges = []
        if verbose:
            log(f"Parsing network...")
        for ind, node in enumerate(self.traced.graph.nodes):
            setattr(node, 'name', node.name.replace('_', '.'))
            if node.op == "call_module":
                if 'fc' in node.name:
                    pass
                tar_node = self._get_layer(node.name)
                setattr(tar_node, 'name', node.name)
                setattr(tar_node, 'index', ind)
                try:
                    raw_params = torch.cat([param.view(-1) for param in tar_node.parameters()], dim=0)
                except:
                    raw_params = None
                paras = self.extract_parameter_features(raw_params)
                graphb_nodes.append(tar_node)
            else:
                paras = torch.zeros(5, dtype=torch.float32)
            nodes[node.name] = {
                "name": node.name,
                "index": ind,
                "type": node.target,
                "parameters": paras,
            }
            for arg in node.args:
                if isinstance(arg, torch.fx.Node):
                    edges.append((arg.name, node.name))
        for _, node in nodes.items():
            node['embedding'] = self.embedding_node(node, verbose=verbose)
        self.nodes = nodes
        self.edges = edges
        self.graphb_nodes = graphb_nodes
        return nodes, edges, graphb_nodes
    
    def grapha(self, verbose:bool = True):
        """
        Convert nodes and edges into a format suitable for graph neural networks.

        Args:
            nodes (dict): A dictionary of node information with embeddings.
            edges (list): A list of edges as tuples (source, target).
            verbose (bool, optional): If log verbose information. Defaults to True.

        Returns:
            dict: A dictionary containing node features and edge indices for GNN input.
        """
        if verbose:
            log("Converting nodes and edges to GNN input format...")
        nodes = self.nodes
        edges = self.edges
        # Extract node embeddings
        node_features = [nodes[node]['embedding'] for node in nodes]
        
        # Convert edge list to edge index tensor
        edge_index = torch.tensor(
            [[nodes[src]['index'], nodes[tgt]['index']] for src, tgt in edges],
            dtype=torch.long
        ).t()

        if verbose:
            log(f"Node features shape: {torch.stack(node_features).shape}")
            log(f"Edge index shape: {edge_index.shape}")

        nodes_and_edges = {
            "node_features": torch.stack(node_features),
            "edge_index": edge_index
        }
        self.graph_A = Data(
            x = nodes_and_edges['node_features'],
            edge_index = nodes_and_edges['edge_index']
        )
        return self.graph_A
    
    def mlp_to_graph(self, layer:torch.nn.Module) -> Data:
        
        """
        Convert an MLP layer into a graph representation.

        Args:
            layer(torch.nn.Module.Linear): Layer.

        Returns:
            Data: A torch_geometric.data.Data object representing the MLP layer.
        """
        assert isinstance(layer, nn.Linear), "Make sure layer is nn.Linear."
        weight = layer.weight
        bias = layer.bias
        in_features = weight.size(1)
        out_features = weight.size(0)

        # Nodes: input and output neurons
        num_nodes = in_features + out_features
        x = torch.zeros(num_nodes, 1)  # Nodes have no meaningful features, use zeros

        # Edges: connections between input and output neurons
        edge_index = []
        edge_attr = []

        for out_idx in range(out_features):
            for in_idx in range(in_features):
                edge_index.append([in_idx, in_features + out_idx])  # Edge: input -> output
                edge_attr.append([weight[out_idx, in_idx].item(), bias[out_idx].item()])  # Weight + bias

        edge_index = torch.tensor(edge_index, dtype=torch.long).t()  # Shape [2, num_edges]
        edge_attr = torch.tensor(edge_attr, dtype=torch.float32)  # Shape [num_edges, 2]

        # Create the Data object
        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)
        try:
            data.layer_name = layer.name
            data.layer_index = layer.index
        except:
            pass
        return data

    def conv_to_graph(self, layer:torch.nn.Module) -> Data:
        """
        Convert an nn.Conv2d layer into a graph representation.

        Args:
            layer (torch.nn.Conv2d): A PyTorch Conv2d layer instance.

        Returns:
            Data: A torch_geometric.data.Data object representing the convolutional layer.
        """
        assert isinstance(layer, nn.Linear), "Make sure layer is nn.Linear."
        # Extract weights and biases
        weight = layer.weight  # Shape: [out_channels, in_channels, kh, kw]
        bias = layer.bias      # Shape: [out_channels] or None

        out_channels, in_channels, kh, kw = weight.shape

        # Nodes: input and output channels
        node_features = []

        # Calculate node features as statistics for each input channel
        for c in range(in_channels):
            channel_weights = weight[:, c, :, :].flatten()  # All weights related to this input channel
            node_features.append([channel_weights.mean().item(), channel_weights.std().item()])  # Mean and std

        node_features = torch.tensor(node_features, dtype=torch.float32)  # Shape [in_channels, 2]

        # Edges: connections between input and output channels
        edge_index = []
        edge_attr = []

        for out_channel in range(out_channels):
            for in_channel in range(in_channels):
                kernel_weights = weight[out_channel, in_channel].flatten()  # Kernel weights for this connection
                edge_index.append([in_channel, in_channels + out_channel])  # Edge: input -> output
                edge_attr.append(kernel_weights.tolist())  # Flattened kernel weights

        edge_index = torch.tensor(edge_index, dtype=torch.long).t()  # Shape [2, num_edges]
        edge_attr = torch.tensor(edge_attr, dtype=torch.float32)  # Shape [num_edges, kh * kw]

        # Add bias as an additional edge attribute (optional)
        if bias is not None:
            for out_channel in range(out_channels):
                edge_attr[out_channel::out_channels, :] += bias[out_channel].item()

        # Create the Data object
        data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)
        data.layer_name = layer.name  # Store the layer name for debugging
        data.layer_index = layer.index
        return data

    def graphb(self, verbose:bool=True):
        """
        Generate neuron-level graphs (graph_B) for all Conv2d and Linear layers in the model.

        This method iterates over `self.graphb_nodes`, which contains the nodes of the computational graph.
        For each node, if it is an instance of `nn.Conv2d` or `nn.Linear`, it generates a subgraph
        representing the layer at the neuron level and appends it to `self.graph_B`.

        Args:
            verbose (bool, optional): If True, logs additional information during processing. Defaults to True.

        Returns:
            list: A list of subgraphs, where each subgraph represents a Conv2d or Linear layer at the neuron level.
        """
        for node in self.graphb_nodes:
            if isinstance(node, nn.Conv2d):
                self.graph_B.append(self.conv_to_graph(node))
            elif isinstance(node, nn.Linear):
                self.graph_B.append(self.mlp_to_graph(node))
        return self.graph_B


class TransformerGraphicalor(LogRedirectMixin, ModelInspector):
    def __init__(self, model:nn.Module, log_path:Optional[str]=None) -> None:
        super().__init__(model, log_path)
        self.layer_level_graph = None
        self.attention_level_graph = []
    
    def _get_statistics(self, tensor:torch.Tensor) -> torch.Tensor:
        pass
    def _get_layer_node_representation(self, layer:nn.Module, input_tensor:torch.Tensor) -> torch.Tensor:
        """
        Get the node representation for a transformer layer.

        Args:
            layer (nn.Module): A transformer layer.
            input_tensor (torch.Tensor): A tensor representing the input to the layer.

        Returns:
            torch.Tensor: A representation of the layer as a node in the graph.
        """
        raise NotImplementedError("Subclasses must implement this method.")
    


if __name__ == '__main__':
    from models import get_model
    resnet50 = get_model('resnet50').cuda()
    g = Graphicalor(resnet50)
    graph = g.grapha()
    print(graph)