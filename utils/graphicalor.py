import os
import torch
import torch.nn as nn
from sentence_transformers import SentenceTransformer
import torch_geometric as tg
from torch_geometric.data import Data
from typing import Optional, Union
from utils.io import LogRedirectMixin, log, generate_name
from torch.fx import symbolic_trace
import numpy as np



class Graphicalor(LogRedirectMixin):
    def __init__(self, network:nn.Module, embedding_model:nn.Module = None, log_path:Optional[str] = None) -> None:
        super().__init__(log_path)
        self.network = network
        if not embedding_model:
            log("No embedding model provided. Using default model: all-MiniLM-L6-v2.", level="WARNING")
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        self.graph_A = None
        self.graph_B = []
        self.traced = symbolic_trace(self.network)
        self.extract_nodes_and_edges()
    
    def get_layer(self, name:str, verbose=True) -> nn.Module:
        """Get a specific layer of model.

        Args:
            name (str): Layer name, split by dot(.), especially, can be 'all'.

        Returns:
            nn.Module: Target layer
        """
        if name == 'all':
            return self.network
        else:
            name_list = name.split('.')
            tar = self.network
            for i in name_list:
                try:
                    i = eval(i)
                except:
                    pass
                if isinstance(i, str):
                    tar = getattr(tar, i)
                elif isinstance(i, int):
                    try:
                        tar = tar[i]
                    except:
                        pass
            return tar

    def embedding_node(self, node:dict, verbose:bool=True):
        """
        Generate an embedding for a node based on its description.

        This function generates a natural language description for a given node 
        in a neural network based on its type and index in the network. The 
        description is then encoded into a vector representation using a pre-trained 
        embedding model.

        Args:
            node (dict): A dictionary containing node information. Expected keys:
                - 'name' (str): The name of the node.
                - 'type' (str): The type of the node (e.g., 'conv', 'relu').
                - 'index' (int): The index of the node in the network.
            verbose (bool, optional): Whether to log the description of the node. Defaults to True.

        Returns:
            np.ndarray: A vector representation of the node's description, generated by the embedding model.

        Notes:
            - The function uses a mapping dictionary to associate node types with 
            natural language descriptions.
            - If the node type is not in the mapping, it defaults to "Other operator."
            - The node index is converted to a human-readable ordinal string (e.g., 'first', 'second').
        
        Example:
            node = {'name': 'conv1', 'type': 'conv', 'index': 1}
            embedding = self.embedding_node(node)
        """

        mapping = {
            'conv': 'Convolution module',
            'linear': 'Linear module',
            'batch_norm': 'BatchNorm activation',
            'relu': 'ReLU activation',
            'max_pool': 'MaxPool function',
            'avg_pool': 'AvgPool function',
            'dropout': 'Dropout function',
            'softmax': 'Softmax function',
            'sigmoid': 'Sigmoid function',
            'tanh': 'Tanh function',
            'other': 'Other operator',
        }
        def get_key(name):
            for k in mapping.keys():
                if k in str(name).lower():
                    return k
            else:
                return 'other'
        def get_index_string(ind):
            if ind == 0:
                return 'input'
            if ind == 1:
                return 'first'
            if ind == 2:
                return 'second'
            if ind == 3:
                return 'third'
            if ind > 3:
                return f"{ind}th"
            
        description = f"The {get_index_string(node['index'])} layer, which is a {mapping[get_key(node['type'])]}."
        if node['parameters'].sum() == 0:
            param_des = "No parameters."
        else:
            param_des = f"Its parameters mean is {node['parameters'][0].item()}, standard deviation is {node['parameters'][1].item()}, minimum is {node['parameters'][2].item()}, maximum is {node['parameters'][3].item()}, total number of parameters is {node['parameters'][4].item()}."
        description += param_des
        log(f"Name: {node['name']} Description: {description}.")
        embbeding = torch.tensor(self.embedding_model.encode(description))
        return embbeding
    
    def embedding_node_simple(self, node:dict, verbose:bool=True):
        pass
    
    def extract_parameter_features(self, parameters):
        """
        Extract fixed-length features from node parameters as a torch.Tensor.

        Args:
            parameters (dict): A dictionary of parameter tensors, typically from `module.named_parameters()`.

        Returns:
            torch.Tensor: A fixed-length tensor representing the parameters, 
                        or a zero tensor if no parameters are present.
        """
        if parameters is None:
            # No parameters: return zero vector
            return torch.zeros(5, dtype=torch.float32)
        all_params = parameters.flatten()
        mean = torch.mean(all_params)
        std = torch.std(all_params)
        min_val = torch.min(all_params)
        max_val = torch.max(all_params)
        param_count = torch.tensor(all_params.numel(), dtype=torch.float32)

        # Feature vector: [mean, std, min, max, param_count]
        return torch.tensor([mean, std, min_val, max_val, param_count], dtype=torch.float32)
    
    def extract_nodes_and_edges(self, verbose:bool=True):
        """Generate nodes and edges from the network.

        Args:
            verbose (bool, optional): If log verbose information. Defaults to True.

        Returns:
            nodes and edges.
        """
        nodes = {}
        graphb_nodes = []
        edges = []
        if verbose:
            log(f"Parsing network...")
        for ind, node in enumerate(self.traced.graph.nodes):
            setattr(node, 'name', node.name.replace('_', '.'))
            if node.op == "call_module":
                tar_node = self.get_layer(node.name)
                try:
                    raw_params = torch.cat(list(tar_node.parameters()))
                except:
                    raw_params = None
                paras = self.extract_parameter_features(raw_params)
                graphb_nodes.append(tar_node)
            else:
                paras = torch.zeros(5, dtype=torch.float32)
            nodes[node.name] = {
                "name": node.name,
                "index": ind,
                "type": node.target,
                "parameters": paras,
            }
            for arg in node.args:
                if isinstance(arg, torch.fx.Node):
                    edges.append((arg.name, node.name))
        for _, node in nodes.items():
            node['embedding'] = self.embedding_node(node, verbose=verbose)
        self.nodes = nodes
        self.edges = edges
        self.graphb_nodes = graphb_nodes
        return nodes, edges, graphb_nodes
    
    def grapha(self, verbose:bool = True):
        """
        Convert nodes and edges into a format suitable for graph neural networks.

        Args:
            nodes (dict): A dictionary of node information with embeddings.
            edges (list): A list of edges as tuples (source, target).
            verbose (bool, optional): If log verbose information. Defaults to True.

        Returns:
            dict: A dictionary containing node features and edge indices for GNN input.
        """
        if verbose:
            log("Converting nodes and edges to GNN input format...")
        nodes = self.nodes
        edges = self.edges
        # Extract node embeddings
        node_features = [nodes[node]['embedding'] for node in nodes]
        
        # Convert edge list to edge index tensor
        edge_index = torch.tensor(
            [[nodes[src]['index'], nodes[tgt]['index']] for src, tgt in edges],
            dtype=torch.long
        ).t()

        if verbose:
            log(f"Node features shape: {torch.stack(node_features).shape}")
            log(f"Edge index shape: {edge_index.shape}")

        nodes_and_edges = {
            "node_features": torch.stack(node_features),
            "edge_index": edge_index
        }
        self.graph_A = Data(
            x = nodes_and_edges['node_features'],
            edge_index = nodes_and_edges['edge_index']
        )
        return self.graph_A

            

if __name__ == '__main__':
    from models import get_model
    resnet50 = get_model('resnet50').cuda()
    g = Graphicalor(resnet50)
    graph = g.grapha()
    print(graph)